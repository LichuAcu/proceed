{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "model = \"gpt-3.5-turbo-1106\"\n",
    "\n",
    "# Load data from CSV file\n",
    "train_path = f\"../data/{model}/train.csv\"\n",
    "test_path = f\"../data/{model}/test.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df['score'].value_counts(ascending=True).plot.barh()\n",
    "plt.title('Scores Distribution in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['Words Per Prompt'] = train_df['prompt'].str.split().apply(len)\n",
    "train_df.boxplot('Words Per Prompt', by='score', grid=False, showfliers=False)\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "score_encoder = preprocessing.LabelEncoder()\n",
    "train_df['label'] = score_encoder.fit_transform(train_df['score'].tolist()) # Turns 0, 0.25, 0.5, 0.75, 1 into 0, 1, 2, 3, 4\n",
    "test_df['label'] = score_encoder.fit_transform(test_df['score'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class TextCleaner():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub(r\"[^a-zA-Z0-9\\s\\n]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text\n",
    "\n",
    "cleaner = TextCleaner()\n",
    "train_df['cleaned_text'] = train_df['prompt'].apply(cleaner.clean_text)\n",
    "test_df['cleaned_text'] = test_df['prompt'].apply(cleaner.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/24964 [00:00<?, ? examples/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 24964/24964 [00:02<00:00, 12439.80 examples/s]\n",
      "Map: 100%|██████████| 10699/10699 [00:00<00:00, 13795.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Convert datasets to tokenized format\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples[\"cleaned_text\"], truncation=True)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_data, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = tokenized_train.remove_columns([col for col in tokenized_train.column_names if col not in ['label', 'input_ids', 'attention_mask']])\n",
    "tokenized_test = tokenized_test.remove_columns([col for col in tokenized_test.column_names if col not in ['label', 'input_ids', 'attention_mask']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 6\n",
    "model = (AutoModelForSequenceClassification\n",
    "        .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "        .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lichu/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(tokenized_train) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    num_train_epochs=2,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    logging_steps=logging_steps,\n",
    "    log_level=\"error\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/782 [00:18<2:17:20, 10.57s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1886\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1887\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1888\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1889\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1890\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/trainer.py:3238\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   3235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3240\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3241\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/trainer.py:3264\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3263\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 3264\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   3265\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:991\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    989\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 991\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[1;32m    992\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    993\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    994\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    995\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    996\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    997\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    998\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    999\u001b[0m )\n\u001b[1;32m   1000\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:811\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    809\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[1;32m    812\u001b[0m     x\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[1;32m    813\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    814\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    815\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    816\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    817\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    818\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:572\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    564\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    565\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    566\u001b[0m         hidden_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    569\u001b[0m         output_attentions,\n\u001b[1;32m    570\u001b[0m     )\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 572\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    573\u001b[0m         hidden_state,\n\u001b[1;32m    574\u001b[0m         attn_mask,\n\u001b[1;32m    575\u001b[0m         head_mask[i],\n\u001b[1;32m    576\u001b[0m         output_attentions,\n\u001b[1;32m    577\u001b[0m     )\n\u001b[1;32m    579\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:516\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    513\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_layer_norm(sa_output \u001b[38;5;241m+\u001b[39m x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    517\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer_norm(ffn_output \u001b[38;5;241m+\u001b[39m sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    519\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:451\u001b[0m, in \u001b[0;36mFFN.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_chunking_to_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/pytorch_utils.py:238\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:457\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[1;32m    456\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n\u001b[0;32m--> 457\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minplace)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs224n/lib/python3.12/site-packages/torch/nn/functional.py:1268\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28minput\u001b[39m, p, training)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
